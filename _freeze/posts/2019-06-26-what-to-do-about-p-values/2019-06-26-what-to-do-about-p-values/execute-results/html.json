{
  "hash": "7b594717a713b44d55164dfc6f5bf602",
  "result": {
    "markdown": "---\ntitle: What to do about p-values?\nauthor: Andy\ndate: '2019-06-26'\ncategories:\n  - Teaching\n  - Statistics Education\n  - R\n---\n\n\n\nIn March, the ASA published a special issue of *The American Statistician* (TAS) related to statistical inference in the 21st century. In the initial article, *Moving to a World Beyond “p < 0.05”*, Wassersein, Schirm, and Lazar (2019) write for the ASA saying,\n\n> \"The *ASA Statement on P-Values and Statistical Significance* stopped just short of recommending that declarations of “statistical significance” be abandoned. We take that step here. We conclude, based on our review of the articles in this special issue and the broader literature, that it is time to stop using the term \"statistically significant\" entirely. Nor should variants such as \"significantly different,\" \"p < 0.05,\" and \"nonsignificant\" survive, whether expressed in words, by asterisks in a table, or in some other way. (p. 2)\"\n\nSince reading this, I have been thinking about how to address these suggestions (mandates?) in our statistics curriculum. The suggestions offered in the article are nice, but a bit big-picture for applied scientists, things like:\n\n- Accept uncertainty\n- Be thoughtful \n- Be open\n- Be modest\n\nRon Wasserstein in his talk at USCOTS wasn't much more helpful in what to do, but gave a gem of a quote when he said,\n\n> \"Small p-values are like a right-swipe in Tinder. It means you have an interest. It doesn't mean you're ready to book the wedding venue.\"\n\nBut how does all of this translate in a statistical methods course (built around the general linear model) for graduate students in the social sciences? That is what I have been thinking about since March, and so far I have a few, albeit very few, ideas abut how to do this. Here are some things I plan on changing/incorporating into the course.\n\n### Interpreting Results from Hypothesis Tests\n\nFirst off, I will be actively discouraging the use of anything related to \"$p<.05$\" or the use of the word \"significance\". I have done this in the past, but this year I am really goiing to go after it. The question is what to do instead? I am going to try using language such as \"consistent with\" or \"compatible with\" in these interpretations. For example,\n\n> The p-value of .003 suggests that the empirical data are inconsistent with the hypothesis that the regression coefficient differs from zero only because of sampling error. This, along with the positive sample slope provide evidence that time spent on homework likely has a positive association with GPA.\n\nThis type of interpretation is not that different than I have had students use in the past. I think the bigger difference is for results with larger p-values. Here the emphasis is \n\n> The p-value of .13 does not provide evidence against the hypothesis that the regression coefficient differs from zero only because of sampling error. While the empirical data are consistent with this hypothesis, it may also be the case that there is a positive relationship between time spent on homework and GPA (as evidenced by the positve sample slope) but the data do not contain enough statistical information to ascertain this relationship.\n\nThe big diffeence is I want to eliminate the \"reject\" or \"fail to reject\" language I have used in the past. In the second case, I also want students to illuminate the idea that data are consistent with multiple hypothesized values. \n\n\n### Confidence Intervals as Compatibility Intervals\n\nWhen teaching about confidence intervals, I am thinking about focusing on them as \"compatibility intervals\" as suggested by Amrhein, Greenland, and McShane (2019). Here are four points I plan on stressing:\n\n- Just because the interval gives the values most compatible with the data, given the assumptions, it doesn’t mean values outside it are incompatible; they are just less compatible.\n- Not all values inside are equally compatible with the data, given the assumptions. The point estimate is the most compatible, and values near it are more compatible than those near the limits.\n- Like the 0.05 threshold from which it came, the default 95\\% used to compute intervals is itself an arbitrary convention.\n- Last, and most important of all, be humble: compatibility assessments hinge on the correctness of the statistical assumptions used to compute the interval. In practice, these assumptions are at best subject to considerable uncertainty.\n\nTo help with these ideas I am going to have students use visual representations of these that make the uncertainty more apparant. In the past I have had students create coefficient plots, but these tended to use lines to show the CIs for each of the regression coefficients. This year I am going to use [Claus Wilke's ungeviz package](https://github.com/wilkelab/ungeviz) to create these plots. This package employs color density to indicate uncertainty; darker more dense color is associated with more certainty and lighter less dense color is associated with less certainty.\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `stat(ndensity)` was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(ndensity)` instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 4 rows containing missing values (`geom_tile()`).\n```\n:::\n\n::: {.cell-output-display}\n![Coefficient plots for a multiple regression model using time spent on homework and level of parent education to predict GPA. The plot on the left shows the type of coefficient plot I used to have students create, and the plot on the right uses color density to show the uncertainty.](2019-06-26-what-to-do-about-p-values_files/figure-html/unnamed-chunk-1-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nThe syntax is straightforward. After fitting a linear model, obtain the coefficient-level output using `tidy()` and then use Wilke's `stat_confidence_density()` function. I found his package documentation quite good and easy to implement. Here is the syntax I used. (The `keith-gpa.csv` data used is available [here](http://zief0002.github.io/epsy-8251/#data).)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit model\nlm.1 = lm(gpa ~ 1 + homework + parent_ed, data = keith)\n\n# Coefficient plot\nbroom::tidy(lm.1) %>%\n  filter(term != \"(Intercept)\") %>%\n  ggplot(aes(x = estimate, y = term)) +\n    stat_confidence_density(aes(moe = std.error, fill = stat(ndensity)), height = 0.15, confidence = 0.68) +\n    geom_point(aes(x = estimate), size = 2) +\n    xlim(-1, 3) +\n    theme_bw() +\n    scale_fill_gradient(low = \"#eff3ff\", high = \"#6baed6\") +\n    theme(\n      panel.grid.major = element_blank(),\n      panel.grid.minor = element_blank()\n      ) +\n    scale_y_discrete(name = \"Coefficients\", labels = c(\"Intercept\", \"Time spent\\non homework\")) +\n    xlab(\"Estimate\")\n```\n:::\n\n\n### Regression Smoothers\n\nI also want students to consider uncertainty in plots of their regression lines. In the past I have used `geom_smooth()` with the argument `se=TRUE` (default). However, this just draws the confidence enevelope as lines, which has the same issues as the earlier coefficient plot. To voercome this, I used ideas from [Felix Schonbrodt](https://www.nicebread.de/visually-weighted-watercolor-plots-new-variants-please-vote/) to bootstrap potential regression lines and overlay them on a plot so that I could implement color density to illustrate uncertainty. I wrote these into a function `stat_watercolor_smooth()` in my [educate package available via github](https://github.com/zief0002/educate). Note that I am NOT an R programmer; at best a script kiddie, so I do not promise these are curated nor great code.\n\nFor example, here is a line fitted using a simple linear regression.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(educate)\n\nggplot(data = keith, aes(x = homework, y = gpa)) +\n  stat_watercolor_smooth(k = 1000, method = \"lm\") +\n  geom_smooth(method = \"lm\", se = FALSE, size = 0.5, color = \"black\") +\n  theme_bw() +\n  xlab(\"Time spent on homework (in hours)\") +\n  ylab(\"GPA (on a 100-pt scale)\")\n```\n:::\n\n\n![](spaghetti.png)\n\nBy omitting the `method=\"lm\"` arguement a loess smoother will be fitted, similar to `geom_smooth()`. This can be useful for evaluating the linearity assumption in regression.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbroom::augment(lm.1) %>%\n  ggplot(aes(x =  .fitted, y = .resid)) +\n    geom_point() +\n    stat_watercolor_smooth(k = 1000) +\n    geom_hline(yintercept = 0, size = 0.5, color = \"black\") +\n    theme_bw() +\n    xlab(\"Model fitted values\") +\n    ylab(\"Model residuals\")\n```\n:::\n\n\n![](resid.png)\n\nThe uncertainty displayed in the plot suggests that empirical values are not inconsistent with the assumption of linearity (i.e., the uncertainty in the conditional mean values encompasses 0). \n\n\n### Density Plots and Uncertainty\n\nI use density plots in these methods courses and have used the `sm.density()` package for many years due to its ability to produce confidence envelopes for particular models. One drawback is that this package uses base R graphics. So this summer I wrote some syntax to implement some of these features using ggplot. These functions are available in my [educate package via github](https://github.com/zief0002/educate). \n\nI used the same idea of  In this package I bootstrap to create a spaghetti plot of hypothetical densities (which produce a \"confidence enevelope\") and then use color density to show uncertainty.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(educate)\n\nggplot(data = keith, aes(x = gpa)) +\n  stat_density_watercolor(k = 1000) +\n  stat_density(size = 0.5, geom = \"line\") +\n  theme_bw() +\n  xlab(\"GPA (on a 100-pt scale)\") +\n  ylab(\"Probability density\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output-display}\n![Probability density plot of the GPA variable. The plot also displays the uncertainty of the density via 1000 bootstrapped densities.](2019-06-26-what-to-do-about-p-values_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\nWe can also use this to evaluate normality assumptions. This is quite useful for examining model assumptions. For example, here I plot the density of the marginal residuals from the previously fitted linear model.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbroom::augment(lm.1) %>%\nggplot(aes(x = .resid)) +\n  stat_density_watercolor(k = 1000, model = \"normal\") +\n  stat_density(size = 0.5, geom = \"line\") +\n  theme_bw() +\n  xlab(\"Model residuals\") +\n  ylab(\"Probability density\")\n```\n\n::: {.cell-output-display}\n![Probability density plot of the model residuals. The plot also displays 1000 bootstrapped densities drawn from a normal distribution.](2019-06-26-what-to-do-about-p-values_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nHere the empirial density associated with the model residuals is not inconsistent with the assumption of normality (at least marginally). \n\n\n### Conclusion\n\nThese are my inital ideas. I am really curious to talk with other statistics educators to hear how they are addressing the *p*-value post TAS publication. \n\n<br /><br />\n\n\n### Reference\n\n<p style=\"text-indent: -22px; margin-left: 22px;\">Amrhein, V., Greenland, S., &amp; McShane, B. (2019). Comment: Retire statistical significance. *Nature, 567*, 305&ndash;307.</p>\n\n<p style=\"text-indent: -22px; margin-left: 22px;\">Wasserstein, R. L., Schirm, A. L., &amp; Lazar, N. A. (2019). Moving to a world Beyond \"p < 0.05.\" *The American Statistician, 73*(sup1), 1&ndash;19. http://doi.org/10.1080/00031305.2019.1583913</p>\n\n\nI have been in a ",
    "supporting": [
      "2019-06-26-what-to-do-about-p-values_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}